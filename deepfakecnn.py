# -*- coding: utf-8 -*-
"""deepFakeCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dww39Jz-JhNGa_tZaW0mXYUPLQt-zrzo
"""

from google.colab import files
files.upload()  # Upload kaggle.json here (this is small and fast)

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# ðŸ”½ Download the real vs fake face dataset
!kaggle datasets download -d ciplab/real-and-fake-face-detection

!unzip real-and-fake-face-detection.zip -d data

import tensorflow_datasets as tfds
import tensorflow as tf
import os
import keras
from keras import layers

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_data = datagen.flow_from_directory(
    'data/real_and_fake_face',
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary',
    subset='training'
)

val_data = datagen.flow_from_directory(
    'data/real_and_fake_face',
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)

def CNN():
  Model=tf.keras.Sequential([
      #128X128->64X64
      layers.Conv2D(64,(5,5),strides=(2,2)),
      layers.LeakyReLU(),
      #64X64->32X32
      layers.Conv2D(128,(5,5),strides=(2,2)),
      layers.LeakyReLU(),
      layers.Flatten(),
      layers.Dense(1,activation='sigmoid')
  ])
  return Model

model=CNN()
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
model.fit(train_data,validation_data=val_data,epochs=10,batch_size=32)

from google.colab import files
uploaded = files.upload()  # Upload fake_image.jpg here

img_path = "fake_image.jpg"  # after upload

print(train_data.class_indices)

from tensorflow.keras.preprocessing import image
import numpy as np

img = image.load_img(img_path, target_size=(128, 128))  # resize to model input
img_array = image.img_to_array(img) / 255.0  # normalize
img_array = np.expand_dims(img_array, axis=0)  # shape (1, 128, 128, 3)

prediction = model.predict(img_array)[0][0]
label = 'Fake' if prediction < 0.5 else 'Real'

print(f"Prediction: {prediction:.2f} â†’ {label}")

from google.colab import files
uploaded = files.upload()  # Upload fake_image.jpg here

img_path="real_image.jpg"
from tensorflow.keras.preprocessing import image
import numpy as np

img = image.load_img(img_path, target_size=(128, 128))  # resize to model input
img_array = image.img_to_array(img) / 255.0  # normalize
img_array = np.expand_dims(img_array, axis=0)  # shape (1, 128, 128, 3)

prediction = model.predict(img_array)[0][0]
label = 'Fake' if prediction < 0.5 else 'Real'

print(f"Prediction: {prediction:.2f} â†’ {label}")

